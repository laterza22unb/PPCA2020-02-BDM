# PPCA2020-02-BDM
In Brazil, grades from the National Secondary Education Examination - Enem are used for access to federal public universities. In addition to the grades, the microdata of this exam has a large amount of information about the students enrolled in the tests that can be used to carry out various analyzes of student performance. Due to the tens of gigabytes of data available, the data must be stored properly, to reduce the processing time for information retrieval. It was proposed a study to analyze whether different data models for storing Enem information in a document-based database can impact the response time of queries to this database. For this, data from 2010 to 2019 were stored using different strategies for data modeling, different replica sizes and cache usage. However, before starting the experiments, it was necessary to pre-process the Enem microdata in order to consolidate the information of the selected decade in a single file. To this end, the following steps were adopted: (i) mapping of common attributes in the selected decade; (ii) definition of rules and premises to standardize the domain of attributes; and (iii) consolidation of data into a single file. This repository contains the scripts adopted for the pre-processing step. 
